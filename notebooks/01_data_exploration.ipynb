{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - Price Data\n",
    "\n",
    "Interactive exploration and validation of collected price data.\n",
    "\n",
    "**Goals:**\n",
    "- Validate data quality\n",
    "- Explore price movements and patterns\n",
    "- Test basic calculations (returns, volatility)\n",
    "- Identify any data issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "data_path = Path('../data/price/daily/sample_universe_2022-10-24_to_2025-10-23.parquet')\n",
    "df = pl.read_parquet(data_path)\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "print(f\"Columns: {df.columns}\")\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    pl.col(\"date\").dt.to_string(\"%Y-%m-%d\").alias(\"ds\")\n",
    "    ).filter(pl.col(\"ds\")==\"2022-12-09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=== DATA SUMMARY ===\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Number of symbols: {df['symbol'].n_unique()}\")\n",
    "print(f\"\\nSymbols: {sorted(df['symbol'].unique().to_list())}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "null_counts = df.null_count()\n",
    "print(null_counts)\n",
    "\n",
    "# Rows per symbol\n",
    "print(\"\\n=== ROWS PER SYMBOL ===\")\n",
    "rows_per_symbol = df.group_by('symbol').agg(pl.len().alias('count')).sort('count', descending=True)\n",
    "print(rows_per_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative prices (should be none)\n",
    "price_cols = ['open', 'high', 'low', 'close', 'adj_close']\n",
    "for col in price_cols:\n",
    "    neg_count = df.filter(pl.col(col) < 0).height\n",
    "    if neg_count > 0:\n",
    "        print(f\"WARNING: {neg_count} negative values in {col}\")\n",
    "    else:\n",
    "        print(f\"✓ {col}: No negative values\")\n",
    "\n",
    "# Check high >= low\n",
    "invalid_hl = df.filter(pl.col('high') < pl.col('low')).height\n",
    "print(f\"\\n{'✓' if invalid_hl == 0 else '✗'} High >= Low: {invalid_hl} violations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Price Movement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic metrics\n",
    "df_metrics = df.with_columns([\n",
    "    # Daily return using adj_close\n",
    "    (pl.col('adj_close').pct_change().over('symbol')).alias('daily_return'),\n",
    "    # Daily range\n",
    "    ((pl.col('high') - pl.col('low')) / pl.col('close')).alias('daily_range_pct'),\n",
    "    # Volume in millions\n",
    "    (pl.col('volume') / 1_000_000).alias('volume_millions')\n",
    "])\n",
    "\n",
    "print(\"Metrics calculated!\")\n",
    "df_metrics.select(['symbol', 'date', 'adj_close', 'daily_return', 'daily_range_pct']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by symbol\n",
    "summary = df_metrics.group_by('symbol').agg([\n",
    "    pl.col('daily_return').mean().alias('avg_daily_return'),\n",
    "    pl.col('daily_return').std().alias('volatility'),\n",
    "    pl.col('volume_millions').mean().alias('avg_volume_M'),\n",
    "    pl.col('adj_close').min().alias('min_price'),\n",
    "    pl.col('adj_close').max().alias('max_price'),\n",
    "]).sort('volatility', descending=True)\n",
    "\n",
    "print(\"\\n=== SUMMARY BY SYMBOL ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price evolution for a few stocks\n",
    "sample_symbols = ['AAPL', 'MSFT', 'NVDA', 'TSLA']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, symbol in enumerate(sample_symbols):\n",
    "    symbol_data = df_metrics.filter(pl.col('symbol') == symbol).sort('date')\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    ax.plot(symbol_data['date'].to_pandas(), symbol_data['adj_close'].to_pandas(), linewidth=1.5)\n",
    "    ax.set_title(f'{symbol} - Adjusted Close Price', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price ($)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily returns distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for symbol in sample_symbols:\n",
    "    symbol_data = df_metrics.filter(pl.col('symbol') == symbol)\n",
    "    returns = symbol_data['daily_return'].drop_nulls().to_pandas()\n",
    "    ax.hist(returns, bins=50, alpha=0.5, label=symbol)\n",
    "\n",
    "ax.set_title('Daily Returns Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Daily Return')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility comparison (last 60 days rolling)\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "for symbol in sample_symbols:\n",
    "    symbol_data = df_metrics.filter(pl.col('symbol') == symbol).sort('date')\n",
    "    \n",
    "    # Calculate 60-day rolling volatility\n",
    "    volatility = (\n",
    "        symbol_data\n",
    "        .select([\n",
    "            'date',\n",
    "            pl.col('daily_return').rolling_std(window_size=60).alias('volatility_60d')\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    ax.plot(volatility['date'].to_pandas(), volatility['volatility_60d'].to_pandas(), label=symbol, linewidth=2)\n",
    "\n",
    "ax.set_title('60-Day Rolling Volatility', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Volatility (Std Dev of Returns)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adjusted vs Unadjusted Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for splits and dividends\n",
    "splits = df.filter(pl.col('stock_splits') > 0)\n",
    "dividends = df.filter(pl.col('dividends') > 0)\n",
    "\n",
    "print(f\"Stock splits: {splits.height} events\")\n",
    "print(f\"Dividends: {dividends.height} events\")\n",
    "\n",
    "if splits.height > 0:\n",
    "    print(\"\\nStock split events:\")\n",
    "    print(splits.select(['symbol', 'date', 'stock_splits', 'close', 'adj_close']))\n",
    "\n",
    "if dividends.height > 0:\n",
    "    print(\"\\nSample dividend events:\")\n",
    "    print(dividends.select(['symbol', 'date', 'dividends', 'close', 'adj_close']).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjustment ratio\n",
    "df_adj = df.with_columns([\n",
    "    ((pl.col('adj_close') / pl.col('close')) - 1.0).alias('adjustment_ratio')\n",
    "])\n",
    "\n",
    "# Find significant adjustments\n",
    "significant_adj = df_adj.filter(pl.col('adjustment_ratio').abs() > 0.01)\n",
    "print(f\"\\nRows with >1% adjustment: {significant_adj.height}\")\n",
    "if significant_adj.height > 0:\n",
    "    print(significant_adj.select(['symbol', 'date', 'close', 'adj_close', 'adjustment_ratio', 'dividends', 'stock_splits']).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Analysis Space\n",
    "\n",
    "Use this section for ad-hoc exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom analysis here\n",
    "# Example: Calculate 30-day forward returns\n",
    "\n",
    "df_forward = df.sort(['symbol', 'date']).with_columns([\n",
    "    # 30-day forward return\n",
    "    ((pl.col('adj_close').shift(-20) / pl.col('adj_close')) - 1.0)\n",
    "    .over('symbol')\n",
    "    .alias('forward_20d_return')\n",
    "])\n",
    "\n",
    "# Show distribution of forward returns\n",
    "print(\"30-day forward return statistics:\")\n",
    "print(df_forward['forward_20d_return'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save any processed data if needed\n",
    "# df_processed.write_parquet('../data/processed/my_analysis.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
