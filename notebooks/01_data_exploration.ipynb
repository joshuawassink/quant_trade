{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration - Price Data\n",
    "\n",
    "Interactive exploration and validation of collected price data.\n",
    "\n",
    "**Goals:**\n",
    "- Validate data quality\n",
    "- Explore price movements and patterns\n",
    "- Test basic calculations (returns, volatility)\n",
    "- Identify any data issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15,040 rows\n",
      "Columns: ['symbol', 'date', 'open', 'high', 'low', 'close', 'adj_close', 'volume', 'dividends', 'stock_splits']\n",
      "\n",
      "Shape: (15040, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>symbol</th><th>date</th><th>open</th><th>high</th><th>low</th><th>close</th><th>adj_close</th><th>volume</th><th>dividends</th><th>stock_splits</th></tr><tr><td>str</td><td>date</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;TSLA&quot;</td><td>2022-10-24</td><td>205.820007</td><td>213.5</td><td>198.589996</td><td>211.25</td><td>211.25</td><td>100446800</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;GOOGL&quot;</td><td>2022-10-24</td><td>101.800003</td><td>102.75</td><td>99.980003</td><td>102.519997</td><td>101.817749</td><td>27176400</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;META&quot;</td><td>2022-10-24</td><td>127.25</td><td>133.479996</td><td>124.57</td><td>129.720001</td><td>128.925232</td><td>63563400</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;NFLX&quot;</td><td>2022-10-24</td><td>290.230011</td><td>290.48999</td><td>280.359985</td><td>282.450012</td><td>282.450012</td><td>13326400</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;JPM&quot;</td><td>2022-10-24</td><td>122.07</td><td>123.099998</td><td>121.330002</td><td>122.379997</td><td>113.659988</td><td>12624200</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌────────┬────────────┬────────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ symbol ┆ date       ┆ open       ┆ high      ┆ … ┆ adj_close ┆ volume    ┆ dividends ┆ stock_spl │\n",
       "│ ---    ┆ ---        ┆ ---        ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ its       │\n",
       "│ str    ┆ date       ┆ f64        ┆ f64       ┆   ┆ f64       ┆ i64       ┆ f64       ┆ ---       │\n",
       "│        ┆            ┆            ┆           ┆   ┆           ┆           ┆           ┆ f64       │\n",
       "╞════════╪════════════╪════════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ TSLA   ┆ 2022-10-24 ┆ 205.820007 ┆ 213.5     ┆ … ┆ 211.25    ┆ 100446800 ┆ 0.0       ┆ 0.0       │\n",
       "│ GOOGL  ┆ 2022-10-24 ┆ 101.800003 ┆ 102.75    ┆ … ┆ 101.81774 ┆ 27176400  ┆ 0.0       ┆ 0.0       │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 9         ┆           ┆           ┆           │\n",
       "│ META   ┆ 2022-10-24 ┆ 127.25     ┆ 133.47999 ┆ … ┆ 128.92523 ┆ 63563400  ┆ 0.0       ┆ 0.0       │\n",
       "│        ┆            ┆            ┆ 6         ┆   ┆ 2         ┆           ┆           ┆           │\n",
       "│ NFLX   ┆ 2022-10-24 ┆ 290.230011 ┆ 290.48999 ┆ … ┆ 282.45001 ┆ 13326400  ┆ 0.0       ┆ 0.0       │\n",
       "│        ┆            ┆            ┆           ┆   ┆ 2         ┆           ┆           ┆           │\n",
       "│ JPM    ┆ 2022-10-24 ┆ 122.07     ┆ 123.09999 ┆ … ┆ 113.65998 ┆ 12624200  ┆ 0.0       ┆ 0.0       │\n",
       "│        ┆            ┆            ┆ 8         ┆   ┆ 8         ┆           ┆           ┆           │\n",
       "└────────┴────────────┴────────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the full dataset\n",
    "data_path = Path('../data/price/daily/sample_universe_2022-10-24_to_2025-10-23.parquet')\n",
    "df = pl.read_parquet(data_path)\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "print(f\"Columns: {df.columns}\")\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns([\n",
    "    pl.col(\"date\").dt.to_string(\"%Y-%m-%d\").alias(\"ds\"),\n",
    "    ((pl.col(\"close\")-pl.col(\"open\"))/pl.col(\"open\")).alias(\"y_true\"),\n",
    "    ((pl.col(\"high\")-pl.col(\"open\"))/pl.col(\"open\")).alias(\"y_pred\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.filter(pl.col(\"ds\")==\"2022-10-24\").select([\"y_true\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.with_columns([\n",
    "    pl.col(\"y_true\").rank().alias(\"true_rank\"),\n",
    "    pl.col(\"y_pred\").rank().alias(\"pred_rank\")\n",
    "]).with_columns(\n",
    "    pl.col(\"pred_rank\").sub(pl.col(\"true_rank\")).alias(\"rank_error\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>mean_error</th><th>mae</th><th>mse</th><th>rmse</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.0</td><td>1.8</td><td>5.2</td><td>2.280351</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌────────────┬─────┬─────┬──────────┐\n",
       "│ mean_error ┆ mae ┆ mse ┆ rmse     │\n",
       "│ ---        ┆ --- ┆ --- ┆ ---      │\n",
       "│ f64        ┆ f64 ┆ f64 ┆ f64      │\n",
       "╞════════════╪═════╪═════╪══════════╡\n",
       "│ 0.0        ┆ 1.8 ┆ 5.2 ┆ 2.280351 │\n",
       "└────────────┴─────┴─────┴──────────┘"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.select([\n",
    "    pl.col(\"rank_error\").mean().alias(\"mean_error\"),\n",
    "    pl.col(\"rank_error\").abs().mean().alias(\"mae\"),\n",
    "    pl.col(\"rank_error\").pow(2).mean().alias(\"mse\"),\n",
    "    pl.col(\"rank_error\").pow(2).mean().sqrt().alias(\"rmse\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=== DATA SUMMARY ===\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Number of symbols: {df['symbol'].n_unique()}\")\n",
    "print(f\"\\nSymbols: {sorted(df['symbol'].unique().to_list())}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "null_counts = df.null_count()\n",
    "print(null_counts)\n",
    "\n",
    "# Rows per symbol\n",
    "print(\"\\n=== ROWS PER SYMBOL ===\")\n",
    "rows_per_symbol = df.group_by('symbol').agg(pl.len().alias('count')).sort('count', descending=True)\n",
    "print(rows_per_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative prices (should be none)\n",
    "price_cols = ['open', 'high', 'low', 'close', 'adj_close']\n",
    "for col in price_cols:\n",
    "    neg_count = df.filter(pl.col(col) < 0).height\n",
    "    if neg_count > 0:\n",
    "        print(f\"WARNING: {neg_count} negative values in {col}\")\n",
    "    else:\n",
    "        print(f\"✓ {col}: No negative values\")\n",
    "\n",
    "# Check high >= low\n",
    "invalid_hl = df.filter(pl.col('high') < pl.col('low')).height\n",
    "print(f\"\\n{'✓' if invalid_hl == 0 else '✗'} High >= Low: {invalid_hl} violations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Price Movement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic metrics\n",
    "df_metrics = df.with_columns([\n",
    "    # Daily return using adj_close\n",
    "    (pl.col('adj_close').pct_change().over('symbol')).alias('daily_return'),\n",
    "    # Daily range\n",
    "    ((pl.col('high') - pl.col('low')) / pl.col('close')).alias('daily_range_pct'),\n",
    "    # Volume in millions\n",
    "    (pl.col('volume') / 1_000_000).alias('volume_millions')\n",
    "])\n",
    "\n",
    "print(\"Metrics calculated!\")\n",
    "df_metrics.select(['symbol', 'date', 'adj_close', 'daily_return', 'daily_range_pct']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by symbol\n",
    "summary = df_metrics.group_by('symbol').agg([\n",
    "    pl.col('daily_return').mean().alias('avg_daily_return'),\n",
    "    pl.col('daily_return').std().alias('volatility'),\n",
    "    pl.col('volume_millions').mean().alias('avg_volume_M'),\n",
    "    pl.col('adj_close').min().alias('min_price'),\n",
    "    pl.col('adj_close').max().alias('max_price'),\n",
    "]).sort('volatility', descending=True)\n",
    "\n",
    "print(\"\\n=== SUMMARY BY SYMBOL ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price evolution for a few stocks\n",
    "sample_symbols = ['AAPL', 'MSFT', 'NVDA', 'TSLA']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, symbol in enumerate(sample_symbols):\n",
    "    symbol_data = df_metrics.filter(pl.col('symbol') == symbol).sort('date')\n",
    "    \n",
    "    ax = axes[idx]\n",
    "    ax.plot(symbol_data['date'].to_pandas(), symbol_data['adj_close'].to_pandas(), linewidth=1.5)\n",
    "    ax.set_title(f'{symbol} - Adjusted Close Price', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price ($)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily returns distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for symbol in sample_symbols:\n",
    "    symbol_data = df_metrics.filter(pl.col('symbol') == symbol)\n",
    "    returns = symbol_data['daily_return'].drop_nulls().to_pandas()\n",
    "    ax.hist(returns, bins=50, alpha=0.5, label=symbol)\n",
    "\n",
    "ax.set_title('Daily Returns Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Daily Return')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility comparison (last 60 days rolling)\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "for symbol in sample_symbols:\n",
    "    symbol_data = df_metrics.filter(pl.col('symbol') == symbol).sort('date')\n",
    "    \n",
    "    # Calculate 60-day rolling volatility\n",
    "    volatility = (\n",
    "        symbol_data\n",
    "        .select([\n",
    "            'date',\n",
    "            pl.col('daily_return').rolling_std(window_size=60).alias('volatility_60d')\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    ax.plot(volatility['date'].to_pandas(), volatility['volatility_60d'].to_pandas(), label=symbol, linewidth=2)\n",
    "\n",
    "ax.set_title('60-Day Rolling Volatility', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Volatility (Std Dev of Returns)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adjusted vs Unadjusted Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for splits and dividends\n",
    "splits = df.filter(pl.col('stock_splits') > 0)\n",
    "dividends = df.filter(pl.col('dividends') > 0)\n",
    "\n",
    "print(f\"Stock splits: {splits.height} events\")\n",
    "print(f\"Dividends: {dividends.height} events\")\n",
    "\n",
    "if splits.height > 0:\n",
    "    print(\"\\nStock split events:\")\n",
    "    print(splits.select(['symbol', 'date', 'stock_splits', 'close', 'adj_close']))\n",
    "\n",
    "if dividends.height > 0:\n",
    "    print(\"\\nSample dividend events:\")\n",
    "    print(dividends.select(['symbol', 'date', 'dividends', 'close', 'adj_close']).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjustment ratio\n",
    "df_adj = df.with_columns([\n",
    "    ((pl.col('adj_close') / pl.col('close')) - 1.0).alias('adjustment_ratio')\n",
    "])\n",
    "\n",
    "# Find significant adjustments\n",
    "significant_adj = df_adj.filter(pl.col('adjustment_ratio').abs() > 0.01)\n",
    "print(f\"\\nRows with >1% adjustment: {significant_adj.height}\")\n",
    "if significant_adj.height > 0:\n",
    "    print(significant_adj.select(['symbol', 'date', 'close', 'adj_close', 'adjustment_ratio', 'dividends', 'stock_splits']).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Analysis Space\n",
    "\n",
    "Use this section for ad-hoc exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom analysis here\n",
    "# Example: Calculate 30-day forward returns\n",
    "\n",
    "df_forward = df.sort(['symbol', 'date']).with_columns([\n",
    "    # 30-day forward return\n",
    "    ((pl.col('adj_close').shift(-20) / pl.col('adj_close')) - 1.0)\n",
    "    .over('symbol')\n",
    "    .alias('forward_20d_return')\n",
    "])\n",
    "\n",
    "# Show distribution of forward returns\n",
    "print(\"30-day forward return statistics:\")\n",
    "print(df_forward['forward_20d_return'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save any processed data if needed\n",
    "# df_processed.write_parquet('../data/processed/my_analysis.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
